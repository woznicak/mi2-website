<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Papers | MI²</title>
  <meta name="description" content="MI2" />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content="Papers | MI²" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/images/cover.png" />
  <meta property="og:description" content="MI2" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Papers | MI²" />
  
  <meta name="twitter:description" content="MI2" />
  <meta name="twitter:image" content="/images/cover.png" />




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="mi²research.html"/>
<link rel="next" href="software.html"/>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>
<style type="text/css">
    .book .book-body .body-inner {
        position: absolute;
        top: -50px;
    }
</style>

<link rel='shortcut icon' type='image/x-icon' href='/favicon.ico' />



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="css/styles.css" type="text/css" />
<link rel="stylesheet" href="css/typography.css" type="text/css" />
<link rel="stylesheet" href="css/toc.css" type="text/css" />
<link rel="stylesheet" href="css/variables.css" type="text/css" />
<link rel="stylesheet" href="css/two-columns-layout.css" type="text/css" />
<link rel="stylesheet" href="css/icons.css" type="text/css" />
<link rel="stylesheet" href="css/team-layout.css" type="text/css" />
<link rel="stylesheet" href="css/research-grants-layout.css" type="text/css" />
<link rel="stylesheet" href="css/images.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>MI².AI</a>
<ul>
<li class="chapter" data-level="" data-path="the-team.html"><a href="the-team.html"><i class="fa fa-check"></i>The Team</a></li>
<li class="chapter" data-level="" data-path="open-positions.html"><a href="open-positions.html"><i class="fa fa-check"></i>Open Positions</a>
<ul>
<li class="chapter" data-level="" data-path="open-positions.html"><a href="open-positions.html#phd-positions-in-2023"><i class="fa fa-check"></i>PhD positions in 2023</a></li>
<li class="chapter" data-level="" data-path="open-positions.html"><a href="open-positions.html#deep-learning-engineer"><i class="fa fa-check"></i>Deep Learning Engineer</a></li>
<li class="chapter" data-level="" data-path="open-positions.html"><a href="open-positions.html#research-software-engineer"><i class="fa fa-check"></i>Research Software Engineer</a></li>
<li class="chapter" data-level="" data-path="open-positions.html"><a href="open-positions.html#post-doc"><i class="fa fa-check"></i>Post-doc</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="contact.html"><a href="contact.html"><i class="fa fa-check"></i>Contact</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="mi2redteam.html"><a href="mi2redteam.html"><i class="fa fa-check"></i>MI²RedTeam</a></li>
<li class="chapter" data-level="" data-path="mi²research.html"><a href="mi²research.html"><i class="fa fa-check"></i>MI²Research</a>
<ul>
<li class="chapter" data-level="" data-path="papers.html"><a href="papers.html"><i class="fa fa-check"></i>Papers</a></li>
<li class="chapter" data-level="" data-path="software.html"><a href="software.html"><i class="fa fa-check"></i>Software</a></li>
<li class="chapter" data-level="" data-path="books.html"><a href="books.html"><i class="fa fa-check"></i>Books</a></li>
<li class="chapter" data-level="" data-path="seminars.html"><a href="seminars.html"><i class="fa fa-check"></i>Seminars</a></li>
<li class="chapter" data-level="" data-path="research-grants.html"><a href="research-grants.html"><i class="fa fa-check"></i>Research grants</a>
<ul>
<li class="chapter" data-level="" data-path="research-grants.html"><a href="research-grants.html#ares-2022-2026"><i class="fa fa-check"></i>ARES 2022-2026</a></li>
<li class="chapter" data-level="" data-path="research-grants.html"><a href="research-grants.html#darling-2022-2024"><i class="fa fa-check"></i>DARLING 2022-2024</a></li>
<li class="chapter" data-level="" data-path="research-grants.html"><a href="research-grants.html#x-lungs-2021-2024"><i class="fa fa-check"></i>X-LUNGS 2021-2024</a></li>
<li class="chapter" data-level="" data-path="research-grants.html"><a href="research-grants.html#homer-2020-2025"><i class="fa fa-check"></i>HOMER 2020-2025</a></li>
<li class="chapter" data-level="" data-path="research-grants.html"><a href="research-grants.html#decovid-2020-2022"><i class="fa fa-check"></i>DeCoviD 2020-2022</a></li>
<li class="chapter" data-level="" data-path="research-grants.html"><a href="research-grants.html#dalex-2018-2022"><i class="fa fa-check"></i>DALEX 2018-2022</a></li>
<li class="chapter" data-level="" data-path="research-grants.html"><a href="research-grants.html#mlgensig-2017-2021"><i class="fa fa-check"></i>MLGenSig 2017-2021</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="mi²solutions.html"><a href="mi²solutions.html"><i class="fa fa-check"></i>MI²Solutions</a></li>
<li class="chapter" data-level="" data-path="mi²education.html"><a href="mi²education.html"><i class="fa fa-check"></i>MI²Education</a>
<ul>
<li class="chapter" data-level="" data-path="teaching.html"><a href="teaching.html"><i class="fa fa-check"></i>Teaching</a>
<ul>
<li class="chapter" data-level="" data-path="teaching.html"><a href="teaching.html#programming-r-2223-summer"><i class="fa fa-check"></i>Programming R 22/23 Summer</a></li>
<li class="chapter" data-level="" data-path="teaching.html"><a href="teaching.html#exploratory-data-analysis-2223-summer"><i class="fa fa-check"></i>Exploratory Data Analysis 22/23 Summer</a></li>
<li class="chapter" data-level="" data-path="teaching.html"><a href="teaching.html#data-visualization-2223-winter"><i class="fa fa-check"></i>Data Visualization 22/23 Winter</a></li>
<li class="chapter" data-level="" data-path="teaching.html"><a href="teaching.html#exploratory-data-analysis-2122-summer"><i class="fa fa-check"></i>Exploratory Data Analysis 21/22 Summer</a></li>
<li class="chapter" data-level="" data-path="teaching.html"><a href="teaching.html#interpretable-machine-learning-2122-summer"><i class="fa fa-check"></i>Interpretable Machine Learning 21/22 Summer</a></li>
<li class="chapter" data-level="" data-path="teaching.html"><a href="teaching.html#case-studies-2122-summer"><i class="fa fa-check"></i>Case Studies 21/22 Summer</a></li>
<li class="chapter" data-level="" data-path="teaching.html"><a href="teaching.html#data-visualization-2122-winter"><i class="fa fa-check"></i>Data Visualization 21/22 Winter</a></li>
<li class="chapter" data-level="" data-path="teaching.html"><a href="teaching.html#exploratory-data-analysis-2021-summer"><i class="fa fa-check"></i>Exploratory Data Analysis 20/21 Summer</a></li>
<li class="chapter" data-level="" data-path="teaching.html"><a href="teaching.html#case-studies-2021-summer"><i class="fa fa-check"></i>Case Studies 20/21 Summer</a></li>
<li class="chapter" data-level="" data-path="teaching.html"><a href="teaching.html#interpretable-machine-learning-2021-summer"><i class="fa fa-check"></i>Interpretable Machine Learning 20/21 Summer</a></li>
<li class="chapter" data-level="" data-path="teaching.html"><a href="teaching.html#data-visualization-2021-winter"><i class="fa fa-check"></i>Data Visualization 20/21 Winter</a></li>
<li class="chapter" data-level="" data-path="teaching.html"><a href="teaching.html#case-studies-1920-summer"><i class="fa fa-check"></i>Case Studies 19/20 Summer</a></li>
<li class="chapter" data-level="" data-path="teaching.html"><a href="teaching.html#interpretable-machine-learning-1920-summer"><i class="fa fa-check"></i>Interpretable Machine Learning 19/20 Summer</a></li>
<li class="chapter" data-level="" data-path="teaching.html"><a href="teaching.html#data-visualization-1920-summer"><i class="fa fa-check"></i>Data Visualization 19/20 Summer</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="beta-bit.html"><a href="beta-bit.html"><i class="fa fa-check"></i>Beta Bit</a></li>
<li class="chapter" data-level="" data-path="responsibleml-blog.html"><a href="responsibleml-blog.html"><i class="fa fa-check"></i>ResponsibleML Blog</a></li>
</ul></li>
<li class="divider"></li>
<li class="social-icons"> 
  <a href="https://github.com/MI2DataLab"> <svg width="17" height="16" viewBox="0 0 17 16" fill="none" xmlns="http://www.w3.org/2000/svg"> <path fill-rule="evenodd" clip-rule="evenodd" d="M8.1951 0.0301564C6.24962 0.0281791 4.36703 0.719084 2.88468 1.97906C1.40234 3.23904 0.417131 4.98573 0.105636 6.90611C-0.205859 8.82649 0.176714 10.795 1.18479 12.459C2.19286 14.1229 3.76055 15.3735 5.6069 15.9865C6.01398 16.0619 6.16475 15.8056 6.16475 15.5895C6.16475 15.3734 6.16475 14.8809 6.16475 14.1974C3.88814 14.7 3.40567 13.1018 3.40567 13.1018C3.25397 12.6065 2.93169 12.181 2.49603 11.9007C1.75726 11.3981 2.55634 11.3981 2.55634 11.3981C2.81531 11.4347 3.06256 11.5297 3.27936 11.676C3.49617 11.8223 3.67686 12.016 3.80772 12.2424C3.91892 12.4441 4.06883 12.6218 4.24887 12.7653C4.42891 12.9088 4.63552 13.0154 4.85684 13.0789C5.07817 13.1424 5.30986 13.1616 5.53861 13.1354C5.76737 13.1091 5.98869 13.0379 6.18987 12.9259C6.22141 12.5125 6.39965 12.1239 6.69243 11.8303C4.87315 11.6243 2.96341 10.9207 2.96341 7.78471C2.95092 6.97206 3.25142 6.18572 3.80269 5.58851C3.55667 4.88199 3.58538 4.10879 3.88311 3.42246C3.88311 3.42246 4.57162 3.20133 6.13459 4.26174C7.47673 3.89324 8.89337 3.89324 10.2355 4.26174C11.7985 3.20133 12.482 3.42246 12.482 3.42246C12.7828 4.10781 12.8133 4.88159 12.5674 5.58851C13.1187 6.18572 13.4192 6.97206 13.4067 7.78471C13.4067 10.9308 11.4919 11.6193 9.66761 11.8052C9.86322 12.0019 10.0143 12.2383 10.1105 12.4984C10.2068 12.7585 10.246 13.0363 10.2255 13.3129C10.2255 14.4085 10.2255 15.293 10.2255 15.5594C10.2255 15.8257 10.3712 16.0318 10.7883 15.9564C12.6289 15.3375 14.1897 14.085 15.1925 12.4222C16.1953 10.7593 16.5748 8.79434 16.2633 6.87768C15.9518 4.96103 14.9696 3.21735 13.4918 1.95765C12.0141 0.697949 10.1369 0.0041503 8.1951 0V0.0301564Z" fill="black"/> </svg> </a> 
  <a href="https://medium.com/responsibleml"> <svg width="17" height="17" xmlns="http://www.w3.org/2000/svg" fill-rule="evenodd" clip-rule="evenodd"><path d="M24 24h-24v-24h24v24zm-4.03-5.649v-.269l-1.247-1.224c-.11-.084-.165-.222-.142-.359v-8.998c-.023-.137.032-.275.142-.359l1.277-1.224v-.269h-4.422l-3.152 7.863-3.586-7.863h-4.638v.269l1.494 1.799c.146.133.221.327.201.523v7.072c.044.255-.037.516-.216.702l-1.681 2.038v.269h4.766v-.269l-1.681-2.038c-.181-.186-.266-.445-.232-.702v-6.116l4.183 9.125h.486l3.593-9.125v7.273c0 .194 0 .232-.127.359l-1.292 1.254v.269h6.274z"/></svg> </a>
  <a href="https://www.facebook.com/MI2DataLab"> <svg width="9" height="17" viewBox="0 0 9 17" fill="none" xmlns="http://www.w3.org/2000/svg"> <path d="M5.2202 16.0741V8.73358H7.59771L7.95951 5.86704H5.2202V4.04531C5.2202 3.21482 5.45278 2.65222 6.58985 2.65222H8.03704V0.107161C7.77861 0.0803704 6.92581 0 5.91795 0C3.8247 0 2.37752 1.33951 2.37752 3.77741V5.89383H0V8.76037H2.37752V16.0741H5.2202Z" fill="black"/> </svg> </a>
  <a href="https://www.linkedin.com/company/mi2datalab"> <svg width="17" height="16" viewBox="0 0 17 16" fill="none" xmlns="http://www.w3.org/2000/svg"> <path d="M16.2913 15.2715V9.73481C16.2913 7.02356 15.7278 4.94019 12.6007 4.94019C11.1075 4.94019 10.0933 5.76783 9.67071 6.56693H9.61437V5.19704H6.65625V15.2715H9.75524V10.2771C9.75524 8.96424 10.0088 7.67997 11.6146 7.67997C13.1923 7.67997 13.2205 9.19256 13.2205 10.3627V15.2715H16.2913Z" fill="black"/> <path d="M0.962891 4.94019H4.46654V15.2715H0.962891V4.94019Z" fill="black"/> <path d="M2.71471 0C1.75668 0 0.962891 0.786075 0.962891 1.79674C0.962891 2.80741 1.72931 3.59348 2.71471 3.59348C3.67274 3.59348 4.46654 2.77934 4.46654 1.79674C4.43917 0.786075 3.67274 0 2.71471 0Z" fill="black"/> </svg> </a>
</li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MI²</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="papers" class="section level2 unnumbered hasAnchor">
<h2>Papers<a href="papers.html#papers" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<script>
document.body.classList.add("two-columns")
document.querySelector(".page-inner section > *:first-child").classList.add("two-columns-layout")
</script>
<div>
<img src="images/consolidated-learning.png">
<a href="https://doi.org/10.1007/s10994-023-06359-0">Consolidated learning: a domain-specific model-free optimization strategy with validation on metaMIMIC benchmarks</a>
<p>
Katarzyna Woźnica, Mateusz Grzyb, Zuzanna Trafas, Przemysław Biecek
</p>
<p>
<strong>Machine Learning (2023)</strong>
</p>
<p>This paper proposes a new formulation of the tuning problem, called consolidated learning, more suited to practical challenges faced by model developers, in which a large number of predictive models are created on similar datasets. We show that a carefully selected static portfolio of hyperparameter configurations yields good results for anytime optimization, while maintaining the ease of use and implementation. We demonstrate the effectiveness of this approach through an empirical study for the XGBoost algorithm and the newly created metaMIMIC benchmarks of predictive tasks extracted from the MIMIC-IV medical database.</p>
</div>
<div>
<img src="images/evaluating-vit-explanations.png">
<a href="https://openaccess.thecvf.com/content/CVPR2023W/XAI4CV/html/Komorowski_Towards_Evaluating_Explanations_of_Vision_Transformers_for_Medical_Imaging_CVPRW_2023_paper.html">Towards Evaluating Explanations of Vision Transformers for Medical Imaging</a>
<p>
Piotr Komorowski, Hubert Baniecki, Przemysław Biecek
</p>
<p>
<strong>CVPR Workshop on Explainable AI for Computer Vision (2023)</strong>
</p>
<p>This paper investigates the performance of various interpretation methods on a Vision Transformer (ViT) applied to classify chest X-ray images. We introduce the notion of evaluating faithfulness, sensitivity, and complexity of ViT explanations. The obtained results indicate that Layerwise relevance propagation for transformers outperforms Local interpretable model-agnostic explanations and Attention visualization, providing a more accurate and reliable representation of what a ViT has actually learned.</p>
</div>
<div>
<img src="images/tlos.png">
<a href="https://doi.org/10.1007/978-3-031-34344-5_9">Hospital Length of Stay Prediction Based on Multi-modal Data towards Trustworthy Human-AI Collaboration in Radiomics</a>
<p>
Hubert Baniecki, Bartlomiej Sobieski, Przemysław Bombiński, Patryk Szatkowski, Przemysław Biecek
</p>
<p>
<strong>International Conference on Artificial Intelligence in Medicine (2023)</strong>
</p>
<p>To what extent can the patient’s length of stay in a hospital be predicted using only an X-ray image? We answer this question by comparing the performance of machine learning survival models on a novel multi-modal dataset created from 1235 images with textual radiology reports annotated by humans. We introduce time-dependent model explanations into the human-AI decision making process. For reproducibility, we open-source code and the TLOS dataset at <a href="https://github.com/mi2datalab/xlungs-trustworthy-los-prediction">this URL</a>.</p>
</div>
<div>
<img src="images/paper_survshap.png">
<a href="https://doi.org/10.1016/j.knosys.2022.110234 ">SurvSHAP(t): Time-dependent explanations of machine learning survival models</a>
<p>
Mateusz Krzyziński, Mikołaj Spytek, Hubert Baniecki, Przemysław Biecek
</p>
<p>
<strong>Knowledge-Based Systems (2023)</strong>
</p>
<p>In this paper, we introduce SurvSHAP(t), the first time-dependent explanation that allows for interpreting survival black-box models. The proposed methods aim to enhance precision diagnostics and support domain experts in making decisions. SurvSHAP(t) is model-agnostic and can be applied to all models with functional output. We provide an accessible implementation of time-dependent explanations in Python at <a href="https://github.com/MI2DataLab/survshap">this URL</a>.</p>
</div>
<div>
<img src="images/paper_iema.png">
<a href="https://doi.org/10.1007/s10618-023-00924-w ">The grammar of interactive explanatory model analysis</a>
<p>
Hubert Baniecki, Dariusz Parzych, Przemyslaw Biecek
</p>
<p>
<strong>Data Mining and Knowledge Discovery (2023)</strong>
</p>
<p>This paper proposes how different Explanatory Model Analysis (EMA) methods complement each other and discusses why it is essential to juxtapose them. The introduced process of Interactive EMA (IEMA) derives from the algorithmic side of explainable machine learning and aims to embrace ideas developed in cognitive sciences. We formalize the grammar of IEMA to describe human-model interaction. We conduct a user study to evaluate the usefulness of IEMA, which indicates that an interactive sequential analysis of a model may increase the accuracy and confidence of human decision making.</p>
</div>
<div>
<img src="images/climate_policy_tracker.png">
<a href="http://arxiv.org/abs/2211.05852 ">Climate Policy Tracker: Pipeline for automated analysis of public climate policies</a>
<p>
Artur Żółkowski, Mateusz Krzyziński, Piotr Wilczyński, Stanisław Giziński, Emilia Wiśnios, Bartosz Pieliński, Julian Sienkiewicz, Przemysław Biecek
</p>
<p>
<strong>NeurIPS Workshop on Tackling Climate Change with Machine Learning (2022)</strong>
</p>
<p>In this work, we use a Latent Dirichlet Allocation-based pipeline for the automatic summarization and analysis of 10-years of national energy and climate plans (NECPs) for the period from 2021 to 2030, established by 27 Member States of the European Union. We focus on analyzing policy framing, the language used to describe specific issues, to detect essential nuances in the way governments frame their climate policies and achieve climate goals.</p>
</div>
<div>
<img src="images/paper_xg.png">
<a href="https://doi.org/10.1109/DSAA54385.2022.10032440">Explainable expected goal models for performance analysis in football analytics</a>
<p>
Mustafa Cavus, Przemyslaw Biecek
</p>
<p>
<strong>International Conference on Data Science and Advanced Analytics (2022)</strong>
</p>
<p>The expected goal provides a more representative measure of the team and player performance which also suit the low-scoring nature of football instead of the score in modern football. This paper proposes an accurate expected goal model trained on 315,430 shots from seven seasons between 2014-15 and 2020-21 of the top-five European football leagues. Moreover, we demonstrate a practical application of aggregated profiles to explain a group of observations on an accurate expected goal model for monitoring the team and player performance.</p>
</div>
<div>
<img src="images/paper_gdf.png">
<a href="https://doi.org/10.1038/s41598-022-21417-8">Multi-omics disease module detection with an explainable Greedy Decision Forest</a>
<p>
Bastian Pfeifer, Hubert Baniecki, Anna Saranti, Przemyslaw Biecek, Andreas Holzinger
</p>
<p>
<strong>Scientific Reports (2022)</strong>
</p>
<p>In this work, we demonstrate subnetwork detection based on multi-modal node features using a novel Greedy Decision Forest (GDF) with inherent interpretability. The latter will be a crucial factor to retain experts and gain their trust in such algorithms. To demonstrate a concrete application example, we focus on bioinformatics, systems biology and particularly biomedicine, but the presented methodology is applicable in many other domains as well. Our proposed explainable approach can help to uncover disease-causing network modules from multi-omics data to better understand complex diseases such as cancer.</p>
</div>
<div>
<img src="images/epp_diagram.png">
<a href="https://www.nature.com/articles/s42256-022-00531-2">Interpretable meta-score for model performance</a>
<p>
Alicja Gosiewska, Katarzyna Woźnica, Przemysław Biecek
</p>
<p>
<strong>Nature Machine Intelligence (2022)</strong>
</p>
<p>Elo-based predictive power (EPP) meta-score that is built on other performance measures and allows for interpretable comparisons of models. Differences between this score have a probabilistic interpretation and can be compared directly between data sets. Furthermore, this meta-score allows for an assessment of ranking fitness. We prove the properties of the Elo-based predictive power meta-score and support them with empirical results on a large-scale benchmark of 30 classification data sets. Additionally, we propose a unified benchmark ontology that provides a uniform description of benchmarks.</p>
</div>
<div>
<img src="images/mini_fairmodels.png">
<a href="http://doi.org/10.32614/RJ-2022-019">fairmodels: a Flexible Tool for Bias Detection, Visualization, and Mitigation in Binary Classification Models</a>
<p>
Jakub Wiśniewski, Przemyslaw Biecek
</p>
<p>
<strong>The R Journal (2022)</strong>
</p>
<p>This article introduces an R package fairmodels that helps to validate fairness and eliminate bias in binary classification models quickly and flexibly. It offers a model-agnostic approach to bias detection, visualization, and mitigation. The implemented functions and fairness metrics enable model fairness validation from different perspectives. In addition, the package includes a series of methods for bias mitigation that aim to diminish the discrimination in the model. The package is designed to examine a single model and facilitate comparisons between multiple models.</p>
</div>
<div>
<img src="images/xai-alzheimer.png">
<a href="https://doi.org/10.1186/s40708-022-00165-5">A robust framework to investigate the reliability and stability of explainable artificial intelligence markers of Mild Cognitive Impairment and Alzheimer’s Disease</a>
<p>
Angela Lombardi, Domenico Diacono, Nicola Amoroso, Przemysław Biecek, Alfonso Monaco, Loredana Bellantuono, Ester Pantaleo, Giancarlo Logroscino, Roberto De Blasi, Sabina Tangaro, Roberto Bellotti
</p>
<p>
<strong>Brain Informatics (2022)</strong>
</p>
<p>In this work, we present a robust framework to (i) perform a threefold classification between healthy control subjects, individuals with cognitive impairment, and subjects with dementia using different cognitive indexes and (ii) analyze the variability of the explainability SHAP values associated with the decisions taken by the predictive models. We demonstrate that the SHAP values can accurately characterize how each index affects a patient’s cognitive status. Furthermore, we show that a longitudinal analysis of SHAP values can provide effective information on Alzheimer’s disease progression.</p>
</div>
<div>
<img src="images/limecraft.png">
<a href="https://link.springer.com/article/10.1007/s10994-022-06204-w">LIMEcraft: handcrafted superpixel selection and inspection for Visual eXplanations</a>
<p>
Weronika Hryniewska, Adrianna Grudzień, Przemysław Biecek
</p>
<p>
<strong>Machine Learning (2022)</strong>
</p>
<p>LIMEcraft enhances the process of explanation by allowing a user to interactively select semantically consistent areas and thoroughly examine the prediction for the image instance in case of many image features. Experiments on several models show that our tool improves model safety by inspecting model fairness for image pieces that may indicate model bias. The code is available at: <a href="https://github.com/MI2DataLab/LIMEcraft">this URL</a>.</p>
</div>
<div>
<img src="images/foolingpd.png">
<a href="https://doi.org/10.1007/978-3-031-26409-2_8">Fooling Partial Dependence via Data Poisoning</a>
<p>
Hubert Baniecki, Wojciech Kretowicz, Przemyslaw Biecek
</p>
<p>
<strong>ECML PKDD (2022)</strong>
</p>
<p>We showcase that PD can be manipulated in an adversarial manner, which is alarming, especially in financial or medical applications where auditability became a must-have trait supporting black-box machine learning. The fooling is performed via poisoning the data to bend and shift explanations in the desired direction using genetic and gradient algorithms.</p>
</div>
<div>
<img src="images/manipulatingshap.png">
<a href="https://doi.org/10.1609/aaai.v36i11.21590">Manipulating SHAP via Adversarial Data Perturbations (Student Abstract)</a>
<p>
Hubert Baniecki, Przemyslaw Biecek
</p>
<p>
<strong>AAAI Conference on Artificial Intelligence (2022)</strong>
</p>
<p>We introduce a model-agnostic algorithm for manipulating SHapley Additive exPlanations (SHAP) with perturbation of tabular data. It is evaluated on predictive tasks from healthcare and financial domains to illustrate how crucial is the context of data distribution in interpreting machine learning models. Our method supports checking the stability of the explanations used by various stakeholders apparent in the domain of responsible AI; moreover, the result highlights the explanations’ vulnerability that can be exploited by an adversary.</p>
</div>
<div>
<img src="images/paper_lncrnas.png">
<a href="https://www.mdpi.com/2072-6694/14/2/439">A Signature of 14 Long Non-Coding RNAs (lncRNAs) as a Step towards Precision Diagnosis for NSCLC</a>
<p>
Anetta Sulewska, Jacek Niklinski, Radoslaw Charkiewicz, Piotr Karabowicz, Przemyslaw Biecek, Hubert Baniecki, Oksana Kowalczuk, Miroslaw Kozlowski, Patrycja Modzelewska, Piotr Majewski et al.
</p>
<p>
<strong>Cancers (2022)</strong>
</p>
<p>The aim of the study was the appraisal of the diagnostic value of 14 differentially expressed long non-coding RNAs (lncRNAs) in the early stages of non-small-cell lung cancer (NSCLC). We established two classifiers. The first recognized cancerous from noncancerous tissues, the second successfully discriminated NSCLC subtypes (LUAD vs. LUSC). Our results indicate that the panel of 14 lncRNAs can be a promising tool to support a routine histopathological diagnosis of NSCLC.</p>
</div>
<div>
<img src="images/python_dalex.png">
<a href="https://www.jmlr.org/papers/v22/20-1473">dalex: Responsible Machine Learning with Interactive Explainability and Fairness in Python</a>
<p>
Hubert Baniecki, Wojciech Kretowicz, Piotr Piątyszek, Jakub Wiśniewski, Przemyslaw Biecek
</p>
<p>
<strong>Journal of Machine Learning Research (2021)</strong>
</p>
<p>We introduce dalex, a Python package which implements a model-agnostic interface for interactive explainability and fairness. It adopts the design crafted through the development of various tools for explainable machine learning; thus, it aims at the unification of existing solutions. This library’s source code and documentation are available under open license at <a href="https://python.drwhy.ai">this URL</a>.</p>
</div>
<div>
<img src="images/checklist.png">
<a href="https://www.sciencedirect.com/science/article/pii/S0031320321002223">Checklist for responsible deep
learning modeling of medical images based on COVID-19 detection studies</a>
<p>
Weronika Hryniewska, Przemysław Bombiński, Patryk Szatkowski, Paulina Tomaszewska, Artur Przelaskowski,
Przemysław Biecek
</p>
<p>
<strong>Pattern Recognition (2021)</strong>
</p>
<p>Our analysis revealed numerous mistakes made at different stages of data acquisition, model development, and explanation construction. In this work, we overview the approaches proposed in the surveyed Machine Learning articles and indicate typical errors emerging from the lack of deep understanding of the radiography domain. The final result is a proposed checklist with the minimum conditions to be met by a reliable COVID-19 diagnostic model.</p>
</div>
<div>
<img src="images/xai_metalearning.png">
<a href="https://arxiv.org/abs/2002.04276">Towards explainable meta-learning</a>
<p>
Katarzyna Woźnica, Przemyslaw Biecek
</p>
<p>
<strong>ECML PKDD Workshop on eXplainable Knowledge Discovery in Data Mining (2021)</strong>
</p>
<p>To build a new generation of meta-models we need a deeper understanding of the importance and effect of meta-features on the model tunability. In this paper, we propose techniques developed for eXplainable Artificial Intelligence (XAI) to examine and extract knowledge from black-box surrogate models. To our knowledge, this is the first paper that shows how post-hoc explainability can be used to improve the meta-learning.</p>
</div>
<div>
<img src="images/prevention_is_better.png">
<a href="https://drive.google.com/file/d/1-B5T3FCAHzDJbOaPtBnf5l9NnK-yhJtZ/view">Prevention is better than cure: a
case study of the abnormalities detection in the chest</a>
<p>
Weronika Hryniewska, Piotr Czarnecki, Jakub Wiśniewski, Przemysław Bombiński, Przemysław Biecek
</p>
<p>
<strong>CVPR Workshop on “Beyond Fairness: Towards a Just, Equitable, and Accountable Computer Vision” (2021)</strong>
</p>
<p>In this paper, we analyze in detail a single use case - a Kaggle competition related to the detection of abnormalities in X-ray lung images. We demonstrate how a series of simple tests for data imbalance exposes faults in the data acquisition and annotation process. Complex models are able to learn such artifacts and it is difficult to remove this bias during or after the training.</p>
</div>
<div>
<img src="images/safe.png">
<p>
<a href="https://www.sciencedirect.com/science/article/pii/S016792362100066X">Simpler is better: Lifting interpretability-performance trade-off via automated feature engineering</a>
</p>
<p>
Alicja Gosiewska, Anna Kozak, Przemysław Biecek
</p>
<p>
<strong>Decision Support Systems (2021)</strong>
</p>
<p>We propose a framework that uses elastic black boxes as supervisor models to create simpler, less opaque, yet still accurate and interpretable glass box models. The new models were created using newly engineered features extracted with the help of a supervisor model. We supply the analysis using a large-scale benchmark on several tabular data sets from the OpenML database.</p>
</div>
<div>
<img src="images/sarscov2.png">
<a href="https://www.sciencedirect.com/science/article/pii/S1896112621000201">The first SARS-CoV-2 genetic variants
of concern (VOC) in Poland: The concept of a comprehensive approach to monitoring and surveillance of emerging
variants</a>
<p>
Radosław Charkiewicz, Jacek Nikliński, Przemysław Biecek, Joanna Kiśluk, Sławomir Pancewicz, Anna
Moniuszko-Malinowska, Robert Flisiak, Adam Krętowski, Janusz Dzięcioł, Marcin Moniuszko, Rafał Gierczyński,
Grzegorz Juszczyk, Joanna Reszeć
</p>
<p>
<strong>Advances in Medical Sciences (2021)</strong>
</p>
<p>This study shows the first confirmed case of SARS-CoV-2 in Poland with the lineage B.1.351 (known as 501Y.V2 South African variant), as well as another 18 cases with epidemiologically relevant lineage B.1.1.7, known as British variant.</p>
</div>
<div>
<img src="images/responsiblecovid.png">
<a href="https://ojs.aaai.org/index.php/AAAI/article/view/17874">Responsible Prediction Making of COVID-19 Mortality
(Student Abstract)</a>
<p>
Hubert Baniecki, Przemyslaw Biecek
</p>
<p>
<strong>AAAI Conference on Artificial Intelligence (2021)</strong>
</p>
<p>During the literature review of COVID-19 related prognosis and diagnosis, we found out that most of the predictive models are not faithful to the RAI principles, which can lead to biassed results and wrong reasoning. To solve this problem, we show how novel XAI techniques boost transparency, reproducibility and quality of models.</p>
</div>
<div>
<img src="images/paper_wildnlp.png">
<a href="https://link.springer.com/chapter/10.1007%2F978-3-030-36718-3_20">Models in the Wild: On Corruption Robustness of Neural NLP Systems</a>
<p>
Barbara Rychalska, Dominika Basaj, Alicja Gosiewska, Przemyslaw Biecek
</p>
<p>
<strong>International Conference on Neural Information Processing (2019)</strong>
</p>
<p>In this paper we introduce WildNLP - a framework for testing model stability in a natural setting where text corruptions such as keyboard errors or misspelling occur. We compare robustness of deep learning models from 4 popular NLP tasks: Q&amp;A, NLI, NER and Sentiment Analysis by testing their performance on aspects introduced in the framework. In particular, we focus on a comparison between recent state-of-the-art text representations and non-contextualized word embeddings. In order to improve robustness, we perform adversarial training on selected aspects and check its transferability to the improvement of models with various corruption types. We find that the high performance of models does not ensure sufficient robustness, although modern embedding techniques help to improve it.</p>
</div>
<div>
<img src="images/paper_auditor.png">
<a href="https://doi.org/10.32614/RJ-2019-036">auditor: an R Package for Model-Agnostic Visual Validation and Diagnostics</a>
<p>
Alicja Gosiewska, Przemyslaw Biecek
</p>
<p>
<strong>The R Journal (2019)</strong>
</p>
<p>This paper describes methodology and tools for model-agnostic auditing. It provides functinos for assessing and comparing the goodness of fit and performance of models. In addition, the package may be used for analysis of the similarity of residuals and for identification of outliers and influential observations. The examination is carried out by diagnostic scores and visual verification. The code presented in this paper are implemented in the auditor package. Its flexible and consistent grammar facilitates the validation models of a large class of models.</p>
</div>
<div>
<img src="images/paper_breakdown.png">
<a href="https://doi.org/10.32614/RJ-2018-072">Explanations of Model Predictions with live and breakDown Packages</a>
<p>
Mateusz Staniak, Przemyslaw Biecek
</p>
<p>
<strong>The R Journal (2018)</strong>
</p>
<p>Complex models are commonly used in predictive modeling. In this paper we present R packages that can be used for explaining predictions from complex black box models and attributing parts of these predictions to input features. We introduce two new approaches and corresponding packages for such attribution, namely live and breakDown. We also compare their results with existing implementations of state-of-the-art solutions, namely, lime (Pedersen and Benesty, 2018) which implements Locally Interpretable Model-agnostic Explanations and iml (Molnar et al., 2018) which implements Shapley values.</p>
</div>
<div>
<img src="images/project-dalex.png">
<a href="https://www.jmlr.org/papers/v22/20-1473">DALEX: Explainers for Complex Predictive Models in R</a>
<p>
Przemyslaw Biecek
</p>
<p>
<strong>Journal of Machine Learning Research (2018)</strong>
</p>
<p>This paper describes a consistent collection of explainers for predictive models, a.k.a. black boxes. Each explainer is a technique for exploration of a black box model. Presented approaches are model-agnostic, what means that they extract useful information from any predictive method irrespective of its internal structure. Each explainer is linked with a specific aspect of a model. Every explainer presented here works for a single model or for a collection of models. In the latter case, models can be compared against each other. Presented explainers are implemented in the DALEX package for R. They are based on a uniform standardized grammar of model exploration which may be easily extended.</p>
</div>
<div>
<img src="images/mini_archivist.png">
<a href="https://github.com/pbiecek/archivist">archivist: An R Package for Managing, Recording and Restoring Data Analysis Results</a>
<p>
Przemyslaw Biecek, Marcin Kosiński
</p>
<p>
<strong>Journal of Statistical Software (2017)</strong>
</p>
<p>Everything that exists in R is an object (Chambers 2016). This article examines what would be possible if we kept copies of all R objects that have ever been created. Not only objects but also their properties, meta-data, relations with other objects and information about context in which they were created. We introduce archivist, an R package designed to improve the management of results of data analysis.</p>
</div>
</div>
<a href ="/" class="mobile-logo"><svg width="30" height="30" viewBox="0 0 30 30" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M28.6799 1.36802V28.68H1.31982V1.32004H28.6799V1.36802ZM30 0H0V30H30V0Z" fill="black"/><path d="M21.6357 21.0469V9.04688H22.9556V21.0469H21.6357Z" fill="black"/><path d="M18.5639 9.04688V21.0469H17.2439V11.0629L13.4039 21.0469H12.2039L8.36395 11.0629V21.0469H7.04395V9.04688H8.95195L12.8039 19.0789L16.6559 9.04688H18.5639Z" fill="black"/></svg></a>

<script>
  const topButtonHtml =
    `<div id="top-button-wrapper" onclick="scrollPageToTop()"><svg id="top-button" width="59" height="96" viewBox="0 0 59 96" fill="none"
     xmlns="http://www.w3.org/2000/svg"
     style="opacity: 0">
    <path d="M19.984 75.8284V84.2844H18.416V75.8284H15.35V74.5124H23.05V75.8284H19.984ZM28.9945 84.4524C28.3785 84.4524 27.8419 84.3404 27.3845 84.1164C26.9365 83.8831 26.5632 83.5518 26.2645 83.1224C25.9752 82.6931 25.7605 82.1658 25.6205 81.5404C25.4805 80.9151 25.4105 80.2011 25.4105 79.3984C25.4105 78.6051 25.4805 77.8958 25.6205 77.2704C25.7605 76.6358 25.9752 76.1038 26.2645 75.6744C26.5632 75.2451 26.9365 74.9184 27.3845 74.6944C27.8419 74.4611 28.3785 74.3444 28.9945 74.3444C29.6105 74.3444 30.1425 74.4611 30.5905 74.6944C31.0479 74.9184 31.4212 75.2451 31.7105 75.6744C32.0092 76.1038 32.2285 76.6358 32.3685 77.2704C32.5085 77.8958 32.5785 78.6051 32.5785 79.3984C32.5785 80.2011 32.5085 80.9151 32.3685 81.5404C32.2285 82.1658 32.0092 82.6931 31.7105 83.1224C31.4212 83.5518 31.0479 83.8831 30.5905 84.1164C30.1425 84.3404 29.6105 84.4524 28.9945 84.4524ZM28.9945 83.1504C29.6945 83.1504 30.1892 82.8891 30.4785 82.3664C30.7679 81.8344 30.9125 81.1158 30.9125 80.2104V78.5724C30.9125 77.6764 30.7679 76.9671 30.4785 76.4444C30.1892 75.9124 29.6945 75.6464 28.9945 75.6464C28.2945 75.6464 27.7999 75.9124 27.5105 76.4444C27.2212 76.9671 27.0765 77.6764 27.0765 78.5724V80.2244C27.0765 81.1204 27.2212 81.8344 27.5105 82.3664C27.7999 82.8891 28.2945 83.1504 28.9945 83.1504ZM35.7651 84.2844V74.5124H39.4191C40.3524 74.5124 41.0617 74.7738 41.5471 75.2964C42.0417 75.8191 42.2891 76.5378 42.2891 77.4524C42.2891 78.3671 42.0417 79.0858 41.5471 79.6084C41.0617 80.1311 40.3524 80.3924 39.4191 80.3924H37.3331V84.2844H35.7651ZM37.3331 79.0904H39.1811C40.1517 79.0904 40.6371 78.6424 40.6371 77.7464V77.1444C40.6371 76.2578 40.1517 75.8144 39.1811 75.8144H37.3331V79.0904Z" fill="black"/>
    <path d="M0.999908 30.2843L29.2842 2.00006L57.5685 30.2843" stroke="black" stroke-width="2"/>
    <path d="M29.2842 58.5686V2.00006" stroke="black" stroke-width="2"/>
</svg></div>`

  function scrollPageToTop () {
    window.scrollTo({top: 0, left: 0, behavior: 'smooth'})
    jQuery('.body-inner').animate({scrollTop: 0}, 'fast');
  }

  function handleMenu() {
    window.sessionStorage.clear()

    if (window.innerWidth < 900){
      const summary = window.document.getElementsByClassName("with-summary")
      if (summary && summary[0]) {
        summary[0].classList.remove('with-summary')
      }
    } else if (document.getElementsByClassName("book")) {
      document.getElementsByClassName("book")[0].classList.add('with-summary')
    }
  }

  window.addEventListener('DOMContentLoaded', (event) => {
    document.querySelector(".page-inner section").innerHTML += topButtonHtml

    handleMenu()

    setTimeout(()=>{
      if (window.innerHeight < window.document.getElementsByClassName("page-inner")[0].clientHeight - 10) {
        document.getElementById("top-button").style.opacity = 1
      }
    }, 2000)
  })

  window.addEventListener('resize', (event) => {
    handleMenu()
  })

  window.addEventListener('load', (event) => {
    const searchInput = document.getElementById('search-box')

    if (searchInput) {
      searchInput.setAttribute('placeholder', 'Search...')

      searchInput.parentElement.innerHTML += `<svg class="input-clear" width="17" height="16" viewBox="0 0 17 16" fill="none" xmlns="http://www.w3.org/2000/svg"><line x1="15.6729" y1="0.53033" x2="1.53077" y2="14.6725" stroke="black" stroke-width="1.5"/><line x1="15.6122" y1="14.6724" x2="1.47011" y2="0.530286" stroke="black" stroke-width="1.5"/></svg>
    `
    }
  });

</script>
            </section>

          </div>
        </div>
      </div>
<a href="mi²research.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="software.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
