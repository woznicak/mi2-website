[["index.html", "MI² Data Lab", " MI² Data Lab MI² is a group of mathematicians and computer scientists that love to play with data. We are spread between Warsaw University of Technology and University of Warsaw. Data Lab is our creative space, place in which we have workshops, seminars and some experiments. Feel free to jump in. Here we are forging new ideas, creating tools, solving problems, doing consulting and sharing our positive attitude. Mission Machine learning is like atomic energy. We develop leaders, skills, methods, tools and good practices so that this potential can be deployed responsibly and sustainably. Vision MI² is a group of experts supporting global initiatives aimed at responsible and sustainable machine learning. We support the development of future leaders of responsible machine learning through internships, PhDs, postdoctoral fellowships and so on. We seek for research grants and business projects to conduct both scientific and applied research. We develop and maintain software and infrastructure necessary to build responsible and sustainable ML. We develop cooperation with international teams working on similar topics. We support companies to implement best practices related to responsible modelling in their operation. We conduct workshops and training on responsible predictive modelling. "],["the-team.html", "The Team", " The Team Members Przemysław Biecek, PhD (Team Leader) Hubert Baniecki MSc student Piotr Czarnecki, PhD student Stanisław Giziński MSc student Weronika Hryniewska PhD student Anna Kozak MSc Piotr Piątyszek BSc student Barbara Rychalska PhD student Tomasz Stanisławek PhD student Paulina Tomaszewska PhD student Jakub Wiśniewski BSc student Katarzyna Woźnica PhD student Hanna Zdulska BSc student Collaborators Przemysław Bombiński, PhD, MD Katarzyna Kobylińska, PhD student Marcin Luckner, PhD Stanisław Łaniewski, PhD student Katarzyna Pękala, MSc Bartek Pieliński, PhD Hanna Piotrowska MA Elżbieta Sienkiewicz, PhD Julian Sienkiewicz, PhD Michał Sokólski, MSc student Patryk Szatkowski, PhD student, MD Trainees Adrianna Grudzień, BSc student Mateusz Grzyb BSc student Hoang Thien Ly BSc student Maria Kałuska BSc student Mateusz Krzyziński BSc student Hubert Ruczyński BSc student Bartosz Sawicki BSc student Szymon Szmajdziński BSc student Zuzanna Trafas BSc student Kinga Ułasik BSc student Artur Żółkowski BSc student Alumni Alicja Gosiewska PhD student Marcin Kosiński, MSc Wojciech Kretowicz, MSc Student Michał Kuźba, MSc Szymon Maksymiuk, Msc Student Tomasz Mikołajczyk PhD Adam Rydelek, BSc Anna Wróblewska, PhD Przemysław Biecek Associate professor at Warsaw University of Technology and the University of Warsaw. Interested in model visualisation, explanatory model analysis, predictive modelling and data science for healthcare. Graduated in software engineering and mathematical statistics. In 2016, he formed the research group MI² which develops methods and tools for predictive model analysis. Research visits: University of California, Davis (2018, USA), Nanyang Technological University (2018, Singapore), Auckland University (2014, 2015, New Zeland), Hasselt University (2010, 2011, 2017, Belgium), Toronto University (2007, Canada), OECD (2013, France), Vienna University (2004, 2005, Austria), Purdue University (2004, USA). Google Scholar: Af0O75cAAAAJ GitHub: pbiecek LinkedIn: pbiecek Hubert Baniecki Master’s student in Data Science at Warsaw University of Technology. Developing and maintaining open-source Python &amp; R packages for explainability of predictive models. Researching explainable machine learning, responsibility, evaluation and adversarial attacks. Google Scholar: H72DRC0AAAAJ GitHub: hbaniecki LinkedIn: hbaniecki Stanisław Giziński A Research Software Engineer and student of Machine Learning at Faculty of Mathematics Informatics and Mechanic, University of Warsaw. His work in the lab focuses on using natural language processing and network analysis to better understand the spread of AI public policies. Interested also in applying machine learning in bioinformatics. Google Scholar: Stanisław Giziński GitHub: Gizzio LinkedIn: stanislaw-gizinski Alicja Gosiewska PhD student in Computer Science at Warsaw University of Technology, holds a Master’s degree in Mathematics. Interested in Machine Learning benchmarks and eXplainable Artificial Intelligence for tabular data. Google Scholar: YiwwR6EAAAAJ GitHub: agosiewska LinkedIn: alicja-gosiewska Weronika Hryniewska PhD candidate in computer science at Warsaw University of Technology. Interested in deep learning modelling on medical images in the context of explainability and responsible AI. Google Scholar: aJeg3IQAAAAJ GitHub: Hryniewska LinkedIn: weronikahryniewska Anna Kozak Graduated in mathematical statistics at Warsaw University of Technology. Interested in explainable artificial intelligence and data visualization. Organizes projects related to education. Google Scholar: JIrqf9kAAAAJ GitHub: kozaka93 LinkedIn: kozakanna Barbara Rychalska PhD candidate in computer science at Warsaw University of Technology. Mainly interested in deep learning for natural language processing (NLP), recommender systems and graph-based learning. Google Scholar: Wp0wHJoAAAAJ LinkedIn: Barbara-Rychalska Tomasz Stanisławek PhD candidate in computer science at Warsaw University of Technology. Mainly interested in deep learning for natural language processing (NLP). Google Scholar: gq8NY_UAAAAJ GitHub: tstanislawek LinkedIn: Tomasz-Stanisławek Paulina Tomaszewska PhD candidate in Computer Science at Warsaw University of Technology. Gained experience in AI at leading universities during: Deep Learning Summer School at Tsinghua University (China), one-semester exchange at Nanyang Technological University (Singapore) and research internships at Gwangju Institute of Science and Technology (South Korea) and Institute of Science and Technology (Austria). Mainly interested in Deep Learning, Computer Vision and Transfer Learning. Google Scholar: eO245iMAAAAJ LinkedIn: paulina-tomaszewska Jakub Wiśniewski Research Software Engineer and third year Data Science student at Warsaw University of Technology. Developer of tools for bias detection and fairness. Currently researching responsible applications of deep learning. President of Data Science Science Club at WUT. Google Scholar: _6eQsXMAAAAJ GitHub: jakwisn LinkedIn: jakwisn Piotr Piątyszek Undergraduate Data Science student at Warsaw University of Technology. Works as a research software engineer on enhancing accessibility and completeness of explainable AI. During pandemic contributes to a system of monitoring covid variants. Github: piotrpiatyszek Katarzyna Woźnica PhD candidate in computer science at Warsaw University of Technology. Graduated in mathematical statistics. Interested in automated machine learning especially in hyperparameter tuning for tabular data. Carrying statistical analysis and predictive modelling for healthcare. Google Scholar: tAQS1gQAAAAJ GitHub: woznicak LinkedIn: woznicak Hanna Zdulska Software engineer and Data Science BSc student at Warsaw University of Technology. Experienced in web scraping, interested in natural language processing (NLP) and legal status of Artificial Intelligence. Beginner chess players. GitHub: HaZdula LinkedIn: Zdulskah Tomasz Mikołajczyk PhD in social sciences, but in recent years has devoted himself to the area of data analysis and visualization. He is interested in the development of the area of explainable artificial intelligence. GitHub: tmikolajczyk LinkedIn: tomasz-mikolajczyk-ds Hanna Piotrowska Information designer, focusing mainly on data visualization, branding and book design, with a strong interest in Data Science and perception studies. Winner of numerous awards, including The Kantar Information Is Beautiful Awards, HOW International Design Awards, Polish Graphic Design Awards and KTR. LinkedIn: hanna-piotrowska Twitter: hannapio Behance: hannapio. Mateusz Grzyb A BSc Data Science student at Warsaw University of Technology. Interested in artificial intelligence, data visualization and metaheuristic optimization. GitHub: PlentyCoups Hoang Thien Ly Pursuing B.S Degree in Mathematics and Data Analysis at Warsaw University of Technology. Interested in working with data, and learning Machine Learning methods. GitHub: lhthien09 LinkedIn: hthienly Mateusz Krzyziński BSc student in Data Science at Warsaw University of Technology. Interested in explainable artificial intelligence, machine learning on graphs and data visualization. Google Scholar: i_r7EUgAAAAJ GitHub: krzyzinskim LinkedIn: krzyzinskim Bartosz Sawicki Works towards BSc degree in Data Science at Warsaw University of Technology. Interested in data visualization. GitHub: SawickiBartosz Szymon Szmajdziński Data Science student at Warsaw University of Technology. Machine learning enthusiast. Interested in automated machine learning and explainable artificial intelligence. GitHub: Szmajsz LinkedIn: szymszmaj Hubert Ruczyński Works towards Bachelor’s degree in Data Science at Warsaw University of Technology. Interested in Maching Learning, Neural Networks and Fairness. GitHub: HubertR21 Zuzanna Trafas A third-year Computer Science student at Poznan University of Technology. Interested in explainable artificial intelligence and computer vision. GitHub: Zuzanna-Trafas LinkedIn: zuzanna-trafas Kinga Ułasik A Data Science student at the Warsaw University of Technology. Interested in data vizualization, machine learning and programming. Besides studies, an astronomy amateur and a musician. GitHub: ARUMHC Maria Kałuska Pursuing a Bachelor’s degree in Data Science at Warsaw University of Technology. Interested in machine learning and neural networks for computer vision. GitHub: kaluskam LinkedIn: Maria-Kałuska Artur Żółkowski Bachelor Data Science student at Warsaw University of Technology. Interested in machine learning and explainable artificial intelligence. GitHub: arturzolkowski LinkedIn: azolkowski "],["contact.html", "Contact", " Contact Faculty of Mathematics and Information Science, Warsaw University of Technology, Koszykowa 75, 00-662 Warszawa VAT: PL 5250005834 "],["mi²-research.html", "MI² Research", " MI² Research On a mission to responsibly build machine learning predictive models. Responsible and sustainable predictive modelling is still a new and developing area. We are conducting a number of studies in this domain that examine predictive models applied to tabular data, computer vision or natural language processing models. We investigate the stability and robustness of various methods, work on explainability and transparency for simple and complex models. As part of our this effort, we develop open source software packages (usually in R and Python) for model explanatory analysis, publish scientific articles describing new methods or investigating properties of already known methods, and create educational materials, recommendations and examples of application in specific domains. If you want to find out more about what we are working on, check out our seminar, which is always open to those interested in responsible and sustainable data science. "],["seminars.html", "Seminars", " Seminars We meet every Monday, 10:00 online or at MI2 DataLab (room 044, Faculty of Mathematics and Information Science, Warsaw University of Technology). Join us at http://meet.google.com/rbo-kgmm-orb Materials from past seminars: https://github.com/mi2-warsaw/MI2DataLab_Seminarium "],["papers-and-books.html", "Papers and Books", " Papers and Books dalex: Responsible Machine Learning with Interactive Explainability and Fairness in Python Hubert Baniecki, Wojciech Kretowicz, Piotr Piątyszek, Jakub Wiśniewski, Przemyslaw Biecek Journal of Machine Learning Research (2021) Explanatory Model Analysis Explore, Explain, and Examine Predictive Models. With examples in R and Python Przemysław Biecek, Tomasz Burzykowski Chapman and Hall/CRC, New York (2021) Checklist for responsible deep learning modeling of medical images based on COVID-19 detection studies Weronika Hryniewska, Przemysław Bombiński, Patryk Szatkowski, Paulina Tomaszewska, Artur Przelaskowski, Przemysław Biecek Pattern Recognition (2021) Simpler is better: Lifting interpretability-performance trade-off via automated feature engineering Alicja Gosiewska, Anna Kozak, Przemysław Biecek Decision Support Systems (2021) The first SARS-CoV-2 genetic variants of concern (VOC) in Poland: The concept of a comprehensive approach to monitoring and surveillance of emerging variants Radosław Charkiewicz, Jacek Nikliński, Przemysław Biecek, Joanna Kiśluk, Sławomir Pancewicz, Anna Moniuszko-Malinowska, Robert Flisiak, Adam Krętowski, Janusz Dzięcioł, Marcin Moniuszko, Rafał Gierczyński, Grzegorz Juszczyk, Joanna Reszeć Advances in Medical Sciences (2021) Responsible Prediction Making of COVID-19 Mortality (Student Abstract) Hubert Baniecki, Przemyslaw Biecek AAAI Conference on Artificial Intelligence (2021) Paper and package: XAI with DALEX for R and Python Package: Fairness with fairmodels Landscape of R packages for XAI Szymon Maksymiuk, Alicja Gosiewska, Przemyslaw Biecek arXiv preprint (2021) Software: COVID-19 Risk Score Paper and package: Model governance with R (MLOps) Prevention is better than cure: a case study of the abnormalities detection in the chest Weronika Hryniewska, Piotr Czarnecki, Jakub Wiśniewski, Przemysław Bombiński, Przemysław Biecek “Beyond Fairness: Towards a Just, Equitable, and Accountable Computer Vision” CVPR Workshop (2021) Towards explainable meta-learning Katarzyna Woźnica, Przemyslaw Biecek XKDD Workshop ECML (2021) fairmodels: A Flexible Tool For Bias Detection, Visualization, And Mitigation Jakub Wiśniewski, Przemyslaw Biecek arXiv preprint (2021) "],["research-grants.html", "Research grants", " Research grants X-LUNGS 2021-2024 X-LUNGS: Responsible Artificial Intelligence for Lung Diseases images/projects_xlungs.jpg The aim of the project is to support the process of identification of lesions visible on CT and lung x-rays. We intend to achieve this goal by building an information system based on artificial intelligence (AI) that will support the radiologist’s work by enriching the images with additional information. The unique feature of the proposed system is a trustworthy artificial intelligence module that: will reduce the image analysis time needed to detect lesions, will make the image evaluation process more transparent, will provide image and textual explanations indicating the rationale behind the proposed recommendation, will be verified for effective collaboration with the radiologist. HOMER 2019-2024 HOMER: Human Oriented autoMated machinE leaRning images/project-homer Open calls for PhD students and post-docs!!! One of the biggest challenges in the state-of-the-art machine learning is dealing with the complexity of predictive models. Recent techniques like deep neural networks, gradient boosting or random forests create models with thousands or even millions of parameters. This makes decisions generated by these black-box models completely opaque. Model obscurity undermines trust in model decisions, hampers model debugging, blocks model auditability, exposes models to problems with concept drift or data drift. Recently, there has been a huge progress in the area of model interpretability, which results in the first generation of model explainers, methods for better understanding of factors that drive model decisions. Despite this progress, we are still far from methods that provide deep explanations, confronted with domain knowledge that satisfies our ,,Right to explanation’’ as listed in the General Data Protection Regulation (GDPR). In this project I am going to significantly advance next generation of explainers for predictive models. This will be a disruptive change in the way how machine learning models are created, deployed, and maintained. Currently to much time is spend on handcrafted models produced in a tedious and laborious try-and-error process. The proposed Human-Oriented Machine Learning will focus on the true bottleneck in development of new algorithms, i.e. on model-human interfaces. The particular directions I consider are (1) developing an uniform grammar for visual model exploration, (2) establishing a methodology for contrastive explanations that describe similarities and differences among different models, (3) advancing a methodology for non-additive model explanations, (4) creating new human-model interfaces for effective communication between models and humans, (5) introducing new techniques for training of interpretable models based on elastic surrogate black-box models, (6) rising new methods for automated auditing of fairness, biases and performance of predictive models. Work on this project is financially supported by the NCN Sonata Bis-9 grant 2019/34/E/ST6/00052. DeCoviD 2021-2022 DeCoviD: Detection of Covid-19 related markers of pulmonary changes using Deep Neural Networks models supported by eXplainable Artificial Intelligence and Cognitive Compressed Sensing images/project-decovid Covid-19 is an infectious respiratory disease. A coronavirus infection leaves permanent ramifications in the respiratory system and beyond. In this situation, tools supporting diagnosis and assessment of lung damage after infection and during Covid-19 treatment are crucial. Preliminary results of analysis of CT images and lung xrays suggest that they can help to quickly assess even asymptomatic cases and facilitate prognosis of response to treatment. There are also reports of usefulness of ultrasound images. The aim of the DeCoviD project is to develop methods and tools to support radiologists in the assessment of lung imaging data for the occurrence of changes caused by Covid-19 disease. The developed solution will allow to automate the identification of pathological changes and will support the diagnosis of coexisting lung diseases as well as diseases of other organs visible on chest images. It will also allow to quantify the severity of lung damage caused by the disease Responsible decision support for radiologists requires models based on interpretable features. Such features will be stored in a hybrid knowledge base powered by two research teams from WUT, working on the basis of two, seemingly opposite, paradigms of image data analysis. The eXplainable Artificial Intelligence (XAI) team will use trained deep networks to automatically extract features that are essential for effective disease detection. Cognitive Compressed Sensing (CCS) will build a set of interpretable semantic features using sparse cognitive representations agreed with a group of cooperating radiologists. Combining these two approaches will achieve high effectiveness of the constructed models, combined with high transparency, clarity and stability of the solution. The DeCoviD project is a part of a broader strategy of competence development in the area of deep learning + XAI + medical applications at the Warsaw University of Technology. More information: https://github.com/MI2DataLab/DeCoviD. Work on this project is financially supported by the IDUB against COVID PW. DALEX 2018-2022 DALEX: Descriptive and model Agnostic Local EXplanations images/project-dalex Research project objectives. Black boxes are complex machine learning models, for example deep neural network, an ensemble of trees of high-dimensional regression model. They are commonly used due to they high performance. But how to understand the structure of a black-box, a model in which decision rules are too cryptic for humans? The aim of the project is to create a methodology for such exploration. To address this issue we will develop methods, that: (1) identify key variables that mostly determine a model response, (2) explain a single model response in a compact visual way through local approximations, (3) enrich model diagnostic plots. Research project methodology. This project is divided into three subprojects - local approximations od complex models (called LIVE), explanations of particular model predictions (called EXPLAIN) and conditional explanations (called CONDA). Expected impact on the development of science. Explanations of black boxes have fundamental implications for the field of predictive and statistical modelling. The advent of big data forces imposes usage of black boxes that are easily able to overperform classical methods. But the high performance itself does not imply that the model is appropriate. Thus, especially in applications to personalized medicine or some regulated fields, one should scrutinize decision rules incorporated in the model. New methods and tools for exploration of black-box models are useful for quick identification of problems with the model structure and increase the interpretability of a black-box Work on this project is financially supported by the NCN Opus grant 2017/27/B/ST6/0130. MLGenSig 2017-2021 MLGenSig: Machine Learning Methods for building of Integrated Genetic Signatures images/project-mlgensig Research project objectives. The main scientific goal of this project is to develop a methodology for integrated genetic signatures based on data from divergent high-throughput techniques used in molecular biology. Integrated signatures base on ensembles of signatures for RNA-seq, DNA-seq, data as well for methylation profiles and protein expression microarrays. The advent of high throughput methods allows to measure dozens of thousands or even millions features on different levels like DNA / RNA / protein. And nowadays in many large scale studies scientists use data from mRNA seq to assess the state of transcriptome, protein microarrays to asses the state of proteome and DNA-seq / bisulfide methylation to assess genome / methylome. Research methodology. Genetic signatures are widely used in different applications, among others: for assessing genes that differentiate cells that are chemo resistant vs. cells that are not, assess the stage of cell pluripotency, define molecular cancer subtypes. For example, in database Molecular Signatures Database v5.0 one can find thousands of gene sets - genetic signatures for various conditions. There are signatures that characterize some cancer cells, pluripotent cells and other groups. But they usually contain relatively small number of genes (around 100), results with them are hard to replicate and they are collection of features that were found significant when independently tested. In most cases signatures are derived from measurements of the same type. Like signatures based of expression of transcripts based on data from microarrays or RNA-seq, or methylation profile or DNA variation. We are proposing a very different approach. First we are going to use machine-learning techniques to create large collections of signatures. Such signatures base on ensembles of small sub-signatures, are more robust and usually have higher precision. Then out of such signatures we are going to develop methodology for meta-signatures, that integrate information from different types of data (transcriptome, proteome, genome). Great examples of such studies are: Progenitor Cell Biology Consortium (PCBC) and The Cancer Genome Atlas (TCGA) studies. For thousands of patients in different cohorts (for PCBC cohorts based on stemness phenotype, for TCGA based on cancer type) measurements of both mRNA, miRNA, DNA and methylation profiles are available. New, large datasets require new methods that take into account high and dense structure of dependencies between features. The task that we are going to solve is to develop methodology that will create genetic signatures that integrate information from different levels of cell functioning. Then we are going to use data from TCGA and PBCB project to assess the quality of proposed methodology. As a baseline we are going to use following methodologies: DESeq, edgeR (for mRNA), casper (for lternative splicing), MethylKit (for RRBS data) and RPPanalyzer for protein arrays. Here is the skeleton for our approach: (1) Use ensembles in order to building a genetic signature. The first step would be to use random forests to train a new signature. Ensembles of sub-signtures are build on bootstrap subsamples and they votes if given sample fit given signature or not. (2) In order to improve signatures we are going to consider various normalization of raw counts. We start with log and rank transformation. (3) In order to improve the process of training an ensemble we are going to use pre-filtering of genes. (4) Another approach is to use Bayesian based methods, that may incorporate the expert knowledge, like belief-based gaussian modelling Research project impact. Genetic profiling is more and more important and has number of application starting from basic classification up to personalized medicine in which patients are profiled against different signatures. Existing tools for genetic signatures have many citations. This we assume that the methodology for integrated genetic profiling will be a very useful for many research groups. It is hard to overestimate the impact of better genetic profiling on medicine. Moreover we build a team of people with knowledge in cancer genetic profiling Work on this project is financially supported by the NCN Opus grant 2016/21/B/ST6/02176. OECD grants OECD grant title images/mi-logo-placeholder.png OECD grant description NCBR grants NCBR grant title images/mi-logo-placeholder.png Innowacyjny moduł systemu analizy danych medycznych i leków dedykowany dla sektora medycznego. Polish Centre for Research and Development POIR.01.01.0100-0328/17 "],["software.html", "Software", " Software Arena Interactive tool for the exploration and comparison of models’ explanations. "],["mi²-solutions.html", "MI² Solutions", " MI² Solutions Our team has experience not only in groundbreaking research, but also in deploying these research into business. We perform champion-challenger evaluations in which we look for potential to increase the effectiveness of predictive models in your company. We take care of the whole life cycle of the predictive models, from reproducibility of results to constant monitoring and continuous improvement of the model. We audit models and analyse the sensitivity and vulnerability of the model to incorrect or unexpected behaviours. We conduct trainings for data-science teams interested in the latest results in the area of responsible predictive modelling. "],["solutions.html", "Solutions", " Solutions "],["trainings.html", "Trainings", " Trainings DALEX for R: Explanation and exploration of machine learning models with R and DALEX images/training_xai A brief introduction to tools for local and global explanations of predictive models using the DALEX library. The short version is 3 hours, the long version is a 2-day training. During the training you will build several predictive models and take a closer look at how they work. Find more materials here: https://github.com/pbiecek/XAIatERUM2020 Fairmodels: Explaining and Checking Fairness for Predictive Models images/training_fairness The tutorial is divided into three parts. First, I talk about fairness in general. Do we have a problem with discrimination, and which areas are affected by it? The second part is related to fairness measures. We discuss the most common statistics for the detection of discrimination. The third part is the hands-on presentation of software that helps to check and visualize fairness. Find more materials here: https://github.com/pbiecek/fairness_xkdd_2021 "],["mi²-education.html", "MI² Education", " MI² Education The demand for predictive modelling skills is growing at a furious rate. Part of our mission is to develop human capital so that predictive modelling is applied responsibly and safely. We take social responsibility seriously and as part of our activities we support the development of data analysis skills among pupils, students and senior professionals alike. "],["teaching.html", "Teaching", " Teaching Classes at MiNI Winter 2021/2022 Data Visualization Techniques for Data Science studies lectures, laboratory, project - Anna Kozak laboratory, project - Hubert Baniecki Summer 2020/2021 Introduction to exploratory data analysis for Mathematics and data analysis studies lectures, laboratory, project - Anna Kozak laboratory - Krzysztof Spaliński Case Studies for Data Science studies lectures - Katarzyna Woźnica XAI1 - laboratory, project - Anna Kozak XAI2 - laboratory, project - Szymon Maksymiuk DL1 - laboratory, project - Weronika Hryniewska DL2 - laboratory, project - Paulina Tomaszewska ML - laboratory, project - Hubert Baniecki RashomonML - laboratory, project - Katarzyna Woźnica Winter 2020/2021 Data Visualization Techniques for Data Science studies lectures, laboratory - Alicja Gosiewska project - Hubert Baniecki Summer 2019/2020 Case Studies for Data Science studies lectures - Alicja Gosiewska Imputation - laboratory, project - Katarzyna Woźnica Reproducibility of scientific papers - laboratory, project - Alicja Gosiewska Interpretability - laboratory, project - Katarzyna Kobylińska Interpretable Machine Learning for Data Science studies lectures, project - Przemysław Biecek Data Visualization for Data Science studies lectures, project - Michał Burdukiewicz Winter 2019/2020 Data Visualization Techniques for Data Science studies lectures, laboratory, project - Michał Burdukiewicz Advanced Programming in R lectures, laboratory, project - Michał Burdukiewicz Summer 2018/2019 Case Studies for Data Science studies lectures, laboratory, project - Alicja Gosiewska Data Visualization lectures, project - Michał Burdukiewicz Interpretable Machine Learning lectures, project - Przemysław Biecek Advanced R lectures, laboratory, project - Przemysław Biecek Winter 2018/2019 Data Visualization Techniques for Data Science studies lectures, project - Przemysław Biecek laboratory, project - Michał Burdukiewicz Classes at MIM Summer 2020/2021 Interpretable Machine Learning lectures, project - Przemysław Biecek Summer 2019/2020 Interpretable Machine Learning lectures, project - Przemysław Biecek Summer 2018/2019 Interpretable Machine Learning lectures, project - Przemysław Biecek "],["beta-bit.html", "Beta Bit", " Beta Bit The Hitchhiker’s Guide to Responsible Machine Learning Przemysław Biecek, Anna Kozak, Aleksander Zawada. 2021 Checklist for responsible deep learning modeling of medical images based on COVID-19 detection studies. (Authors: Weronika Hryniewska, Przemysław Bombiński, Patryk Szatkowski, Paulina Tomaszewska, Artur Przelaskowski, Przemysław Biecek.) Simpler is better: Lifting interpretability-performance trade-off via automated feature engineering. (Authors: Alicja Gosiewska, Anna Kozak, Przemysław Biecek.) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
