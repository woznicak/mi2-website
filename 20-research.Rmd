# MI² Research  {-}

On a mission to responsibly build machine learning predictive models.

....

## Papers {-}

<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-8jgo{border-color:#ffffff;text-align:center;vertical-align:top}
.tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}
</style>

<table>
  <tr><th class="tg-8jgo">
  <a href="http://dalex.drwhy.ai/"><img src="images/mini_dalex.png" height="180"></a></th><th>Paper and package: <a href="http://dalex.drwhy.ai/">XAI with DALEX for R and Python</a>
  </th></tr>
  <tr><th class="tg-8jgo">
  <a href="https://pbiecek.github.io/ema/"><img src="images/mini_ema.png" height="180"></a></th><th>Book: <a href="https://pbiecek.github.io/ema/">Explanatory Model Analysis</a>
  </th></tr>
  <tr><th class="tg-8jgo">
    <a href="https://modeloriented.github.io/fairmodels/"><img src="images/mini_fairmodels.png" height="180"></a></th><th>Package: <a href="https://modeloriented.github.io/fairmodels/">Fairness with fairmodels</a>
  </th></tr>
  <tr><th class="tg-8jgo">
    <a href="http://xai-tools.drwhy.ai/"><img src="images/mini_lungs.png" height="180"></a><</th><th>Paper: <a href="http://xai-tools.drwhy.ai/">Landscape of R packages for XAI</a>
  </th></tr>
  <tr><th class="tg-8jgo">
    <a href="https://crs19.pl/"><img src="images/mini_crs.png" height="180"></a></th><th>Software: <a href="https://crs19.pl/">COVID-19 Risk Score</a>
  </th></tr>
  <tr><th class="tg-8jgo">
    <a href="https://rai-covid.drwhy.ai/"><img src="images/mini_crai.png" height="180"></a></th><th>Paper: <a href="https://rai-covid.drwhy.ai/">Responsible ML for COVID-19</a>
  </th></tr>
  <tr><th class="tg-8jgo">
    <a href="https://github.com/pbiecek/archivist"><img src="images/mini_archivist.png" height="180"></a></th><th>Paper and package: <a href="https://github.com/pbiecek/archivist">Model governance with R (MLOps)</a>
  </th></tr>
  <tr><th class="tg-8jgo">
    <a href="https://www.sciencedirect.com/science/article/pii/S016792362100066X"><img src="images/safe.png" height="180"></a></th><th>Paper: <a href="https://www.sciencedirect.com/science/article/pii/S016792362100066X">Simpler is better</a>
    </th>
  </tr>
</table>


## Research grants  {-}


### HOMER 2019-2024 {-}

#### HOMER: Human Oriented autoMated machinE leaRning {-}

![images/project-homer](images/project-homer.png)

**Open calls for PhD students and post-docs!!!**

One of the biggest challenges in the state-of-the-art machine learning is dealing with the complexity of predictive models. Recent techniques like deep neural networks, gradient boosting or random forests create models with thousands or even millions of parameters. This makes decisions generated by these black-box models completely opaque. Model obscurity undermines trust in model decisions, hampers model debugging, blocks model auditability, exposes models to problems with concept drift or data drift.

Recently, there has been a huge progress in the area of model interpretability, which results in the first generation of model explainers, methods for better understanding of factors that drive model decisions. Despite this progress, we are still far from methods that provide deep explanations, confronted with domain knowledge that satisfies our ,,Right to explanation'' as listed in the General Data Protection Regulation (GDPR).

In this project I am going to significantly advance next generation of explainers for predictive models. This will be a disruptive change in the way how machine learning models are created, deployed, and maintained. Currently to much time is spend on handcrafted models produced in a tedious and laborious try-and-error process. The proposed Human-Oriented Machine Learning will focus on the true bottleneck in development of new algorithms, i.e. on model-human interfaces.

The particular directions I consider are (1) developing an uniform grammar for visual model exploration, (2) establishing a methodology for contrastive explanations that describe similarities and differences among different models, (3) advancing a methodology for non-additive model explanations, (4) creating new human-model interfaces for effective communication between models and humans, (5) introducing new techniques for training of interpretable models based on elastic surrogate black-box models, (6) rising new methods for automated auditing of fairness, biases and performance of predictive models.

**Work on this project is financially supported by the NCN Sonata Bis-9 grant 2019/34/E/ST6/00052.**


### DeCoviD 2021-2022 {-}

#### DeCoviD: Detection of Covid-19 related markers of pulmonary changes using Deep Neural Networks models supported by eXplainable Artificial Intelligence and Cognitive Compressed Sensing 

![images/project-decovid](images/project-decovid.png)

Covid-19 is an infectious respiratory disease. A coronavirus infection leaves permanent ramifications in the respiratory system and beyond. In this situation, tools supporting diagnosis and assessment of lung damage after infection and during Covid-19 treatment are crucial. Preliminary results of analysis of CT images and lung xrays suggest that they can help to quickly assess even asymptomatic cases and facilitate prognosis of response to treatment. There are also reports of usefulness of ultrasound images.

The aim of the DeCoviD project is to develop methods and tools to support radiologists in the assessment of lung imaging data for the occurrence of changes caused by Covid-19 disease. The developed solution will allow to automate the identification of pathological changes and will support the diagnosis of coexisting lung diseases as well as diseases of other organs visible on chest images. It will also allow to quantify the severity of lung damage caused by the disease

Responsible decision support for radiologists requires models based on interpretable features. Such features will be stored in a hybrid knowledge base powered by two research teams from WUT, working on the basis of two, seemingly opposite, paradigms of image data analysis. The eXplainable Artificial Intelligence (XAI) team will use trained deep networks to automatically extract features that are essential for effective disease detection. Cognitive Compressed Sensing (CCS) will build a set of interpretable semantic features using sparse cognitive representations agreed with a group of cooperating radiologists. Combining these two approaches will achieve high effectiveness of the constructed models, combined with high transparency, clarity and stability of the solution.

The DeCoviD project is a part of a broader strategy of competence development in the area of deep learning + XAI + medical applications at the Warsaw University of Technology. 

More information: https://github.com/MI2DataLab/DeCoviD.

**Work on this project is financially supported by the IDUB against COVID PW.**


### DALEX 2018-2022  {-}

#### DALEX: Descriptive and model Agnostic Local EXplanations {-}

![images/project-dalex](images/project-dalex.png)

**Research project objectives.** Black boxes are complex machine learning models, for example deep neural network, an ensemble of trees of high-dimensional regression model. They are commonly used due to they high performance. But how to understand the structure of a black-box, a model in which decision rules are too cryptic for humans? The aim of the project is to create a methodology for such exploration. To address this issue we will develop methods, that: (1) identify key variables that mostly determine a model response, (2) explain a single model response in a compact visual way through local approximations, (3) enrich model diagnostic plots.

**Research project methodology.** This project is divided into three subprojects - local approximations od complex models (called LIVE), explanations of particular model predictions (called EXPLAIN) and conditional explanations (called CONDA).

**Expected impact on the development of science.** Explanations of black boxes have fundamental implications for the field of predictive and statistical modelling. The advent of big data forces imposes usage of black boxes that are easily able to overperform classical methods. But the high performance itself does not imply that the model is appropriate. Thus, especially in applications to personalized medicine or some regulated fields, one should scrutinize decision rules incorporated in the model. New methods and tools for exploration of black-box models are useful for quick identification of problems with the model structure and increase the interpretability of a black-box

**Work on this project is financially supported by the NCN Opus grant 2017/27/B/ST6/0130.**



### MLGenSig 2017-2021   {-}

#### MLGenSig: Machine Learning Methods for building of Integrated Genetic Signatures  {-}

![images/project-mlgensig](images/project-mlgensig.png)

**Research project objectives.** The main scientific goal of this project is to develop a methodology for integrated genetic signatures based on data from divergent high-throughput techniques used in molecular biology. Integrated signatures base on ensembles of signatures for RNA-seq, DNA-seq, data as well for methylation profiles and protein expression microarrays. The advent of high throughput methods allows to measure dozens of thousands or even millions features on different levels like DNA / RNA / protein. And nowadays in many large scale studies scientists use data from mRNA seq to assess the state of transcriptome, protein microarrays to asses the state of proteome and DNA-seq / bisulfide methylation to assess genome / methylome.

**Research methodology.** Genetic signatures are widely used in different applications, among others: for assessing genes that differentiate cells that are chemo resistant vs. cells that are not, assess the stage of cell pluripotency, define molecular cancer subtypes. For example, in database Molecular Signatures Database v5.0 one can find thousands of gene sets - genetic signatures for various conditions. There are signatures that characterize some cancer cells, pluripotent cells and other groups. But they usually contain relatively small number of genes (around 100), results with them are hard to replicate and they are collection of features that were found significant when independently tested. In most cases signatures are derived from measurements of the same type. Like signatures based of expression of transcripts based on data from microarrays or RNA-seq, or methylation profile or DNA variation. We are proposing a very different approach. First we are going to use machine-learning techniques to create large collections of signatures. Such signatures base on ensembles of small sub-signatures, are more robust and usually have higher precision. Then out of such signatures we are going to develop methodology for meta-signatures, that integrate information from different types of data (transcriptome, proteome, genome). Great examples of such studies are: Progenitor Cell Biology Consortium (PCBC) and The Cancer  Genome Atlas (TCGA) studies. For thousands of patients in different cohorts (for PCBC cohorts based on stemness phenotype, for TCGA based on cancer type) measurements of both mRNA, miRNA, DNA and methylation profiles are available. New, large datasets require new methods that take into account high and dense structure of dependencies between features. The task that we are going to solve is to develop methodology that will create genetic signatures that integrate information from different levels of cell functioning. Then we are going to use data from TCGA and PBCB project to assess the quality of proposed methodology. As a baseline we are going to use following methodologies: DESeq, edgeR (for mRNA), casper (for lternative splicing), MethylKit (for RRBS data) and RPPanalyzer for protein arrays.

Here is the skeleton for our approach: (1) Use ensembles in order to building a genetic signature. The first step would be to use random forests to train a new signature. Ensembles of sub-signtures are build on bootstrap subsamples and they votes if given sample fit given signature or not. (2) In order to improve signatures we are going to consider various normalization of raw counts. We start with log and rank transformation. (3) In order to improve the process of training an ensemble we are going to use pre-filtering of genes. (4) Another approach is to use Bayesian based methods, that may incorporate the expert knowledge, like belief-based gaussian modelling

**Research project impact.** Genetic profiling is more and more important and has number of application starting from basic classification up to personalized medicine in which patients are profiled against different signatures. Existing tools for genetic signatures have many citations. This we assume that the methodology for integrated genetic profiling will be a very useful for many research groups. It is hard to overestimate the impact of better genetic profiling on medicine. Moreover we build a team of people with knowledge in cancer genetic profiling


**Work on this project is financially supported by the NCN Opus grant 2016/21/B/ST6/02176.**


### OECD grants  {-}

### NCBR grants  {-}

* Innowacyjny moduł systemu analizy danych medycznych i leków dedykowany dla sektora medycznego. Polish Centre for Research and Development POIR.01.01.0100-0328/17

+ NCBR grants  - ADD DESCRIPTION
